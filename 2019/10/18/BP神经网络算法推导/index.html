<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title> BP神经网络算法推导 | DongMing Tech</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script></head></html><body><main class="content"><section class="outer"><article id="post-BP神经网络算法推导" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name"> BP神经网络算法推导</h1></header><div class="article-meta"> <a href="/2019/10/18/BP神经网络算法推导/" class="article-date"><time datetime="2019-10-18T08:21:13.000Z" itemprop="datePublished">2019-10-18</time></a></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h1 id="BP神经网络"><a href="#BP神经网络" class="headerlink" title="BP神经网络"></a>BP神经网络</h1><p>BP神经网络是一种多层前馈神经网络，信号前向传播，误差反向传播，采用误差反向传播算法。<br>BP算法以误差平方为目标函数，采用梯度下降计算目标函数的最小值。<br>本文主要记录BP算法的数学推导过程，仅供备忘，完全参考：<a href="https://blog.csdn.net/qq_32865355/article/details/80260212" target="_blank" rel="noopener">https://blog.csdn.net/qq_32865355/article/details/80260212</a></p><p>BP神经网络主要分为两个过程：<br>1.数据前向传播，依次经过输入层，隐含层，最后到达输出层<br>2.误差反向传播，从输出层到隐含层，最后到达输入层，并依次调节各层的连接权重及偏置。</p><h1 id="记号说明"><a href="#记号说明" class="headerlink" title="记号说明"></a>记号说明</h1><p>$n_l$:第l层的神经元的个数<br>$f(.)$:神经元激活函数<br>$W^{(l)}$:第l-1层到l层的权重矩阵<br>$w_{ij}^{(l)}$:第l-j层中的第j个神经元到第l层中的i个神经元的连接权重<br>$b^{(l)}$:第l-1层到l层的偏置<br>$z^{(l)}$:第l层的神经元的状态<br>$a^{(l)}$:第l层的神经元的输出值</p><h1 id="BP三层神经网络结构"><a href="#BP三层神经网络结构" class="headerlink" title="BP三层神经网络结构:"></a>BP三层神经网络结构:</h1><p><img src="/2019/10/18/BP神经网络算法推导/bp.jpg" alt></p><p>输入数据：$X=(x_1,x_2,x_3)^T$<br>一个隐藏层，其有三个节点<br>一个输出层，其有两个节点</p><h1 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h1><p>第二层神经元的状态及输出值分别：<br>$z_1^{(2)}=w_{11}^{(2)}x_1+w_{12}^{(2)}x_2+w_{13}^{(2)}x_3+b_{1}^{(2)}$<br>$z_2^{(2)}=w_{21}^{(2)}x_1+w_{22}^{(2)}x_2+w_{23}^{(2)}x_3+b_{2}^{(2)}$<br>$z_3^{(2)}=w_{31}^{(2)}x_1+w_{32}^{(2)}x_2+w_{33}^{(2)}x_3+b_{3}^{(2)}$<br>$a_1^{(2)}=f(z_1^{(2)})$<br>$a_2^{(2)}=f(z_2^{(2)})$<br>$a_3^{(2)}=f(z_3^{(2)})$</p><p>第三层神经元的状态及输出值分别：<br>$z_1^{(3)}=w_{11}^{(3)}x_1+w_{12}^{(3)}x_2+w_{13}^{(3)}x_3+b_{1}^{(3)}$<br>$z_2^{(3)}=w_{21}^{(3)}x_1+w_{22}^{(3)}x_2+w_{23}^{(3)}x_3+b_{2}^{(3)}$<br>$a_1^{(3)}=f(z_1^{(3)})$<br>$a_2^{(3)}=f(z_2^{(3)})$</p><p>可得：<br>$z^{(l)}=W^{(l)}a^{(l-1)}+b^{(l)}$<br>$a^{(l)}=f(z^{(l)})$<br>$2 \leq l \leq L$</p><h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p>某一个训练数据$(x^{(i)},y^{(i)})$的代价函数:<br>$E_{(i)}=\frac{1}{2}\sum_{j=1}^{n}(y_j^{(i)}-o_j^{(i)})^2$</p><p>$y^{(i)}$为期望输出，$o^{(i)}$为神经网络实际输出，<br>所有训练样本的总体代价函数：<br>$E_{(total)}=\frac{1}{N}\sum_{i=1}^{N}E_{(i)}$</p><p>目标是调整各层的权重W和偏置b,使得代价函数最小</p><p>采用随机梯度下降算法，可得如下参数更新公式：<br>$\begin{align*} W^{(l)}&amp;=W^{(l)}+(-1\eta )\frac{\partial E_{total}}{\partial W^{(l)}} \\\\&amp;=W^{(l)}-\frac{\eta}{N}\sum_{i=1}^N\frac{\partial E_{(i)}}{\partial W^{(l)}} \end{align*}$<br>$\begin{align*} b^{(l)}&amp;=b^{(l)}+(-1\eta )\frac{\partial E_{total}}{\partial b^{(l)}} \\\\&amp;=b^{(l)}-\frac{\eta}{N}\sum_{i=1}^N\frac{\partial E_{(i)}}{\partial b^{(l)}} \end{align*}$<br>由上面公式可知，只需要求得$E_{(i)}$对参数W和b的偏导，即$\frac{\partial E_{(i)}}{\partial W^{(l)},\frac{\partial E_{(i)}}{\partial b^{(l)}$,即可得到参数的迭代更新公式。<br>$E_{(i)}$为单个数据的误差，简记为E。</p><h1 id="输出层参数求导"><a href="#输出层参数求导" class="headerlink" title="输出层参数求导"></a>输出层参数求导</h1><p>$\begin{align*} E&amp;=\frac{1}{2}\left((y_1-a_1^{(3)})^2+(y_2-a_2^{(3)})^2\right )\\\\&amp;=\frac{1}{2}\left((y_1-f(z_1^{(3)}))^2+(y_2-f(z_2^{(3)}))^2\right )\\\\&amp;=\frac{1}{2}\left((y_1-f(w_{11}^{(3)}a_{1}^{(2)}+w_{12}^{(3)}a_{2}^{(2)}+w_{13}^{(3)}a_{3}^{(2)}+b_1^{(3)}))^2+(y_2-f(w_{21}^{(3)}a_{1}^{(2)}+w_{22}^{(3)}a_{2}^{(2)}+w_{23}^{(3)}a_{3}^{(2)}+b_2^{(3)}))^2\right)\end{align*}$<br>对连接权重参数w求偏导：<br>$\begin{align*} \frac{\partial E}{\partial w_{11}^{(3)}}&amp;=\frac{1}{2}\cdot 2(y_1-a_1^{(3)})^2(-\frac{\partial{a_1^{(3)}}}{w_{11}^{(3)}})\\\\&amp;=-(y_1-a_1^{(3)})f’(z_1^{(3)})\frac{\partial{z_1^{(3)}}}{w_{11}^{(3)}}\\\\&amp;=-(y_1-a_1^{(3)})f’(z_1^{(3)})a_1^{(2)}\end{align*}$</p></div><footer class="article-footer"> <a data-url="https://dongmingtech.com/2019/10/18/BP神经网络算法推导/" data-id="ck1vz8vlt0000xvlm7yst04qh" class="article-share-link">分享</a><ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ai/">ai</a></li></ul></footer><i class="fe fe-bar-chart"></i> <span class="post-count">890</span>字 &emsp;<i class="fe fe-clock"></i> <span class="post-count">4</span>分钟</div><nav class="article-nav"> <a href="/2019/10/17/Hexo中支持MathJAX/" class="article-nav-link"><strong class="article-nav-caption">后一篇</strong><div class="article-nav-title">Hexo中支持MathJAX</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"9d46fabb0c2dcd2cc3f2",clientSecret:"aa1cb25a344c0e97d83609a255dbcdc43a358282",repo:"blogposts",owner:"cfreebuf",admin:["cfreebuf"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by"> &emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">访客数:<span id="busuanzi_value_site_uv"></span></span>&emsp;</div></div><ul class="list-inline"><ul class="list-inline"><li>全站共<span class="post-count">3.3k</span>字</li></ul><li>&copy; 2019 DongMing Tech</li><li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li><li>Theme <a href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li></ul></div></footer></main><aside class="sidebar sidebar-specter"> <button class="navbar-toggle"></button><nav class="navbar"><div class="logo"> <a href="/"><img src="/images/main.svg" alt="DongMing Tech"></a></div><ul class="nav nav-main"><li class="nav-item"> <a class="nav-item-link" href="/">主页</a></li><li class="nav-item"> <a class="nav-item-link" href="/archives">归档</a></li><li class="nav-item"> <a class="nav-item-link" href="/gallery">相册</a></li><li class="nav-item"> <a class="nav-item-link" href="/about">关于</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> 搜索</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop"><i class="fe fe-rocket"></i></div></li><li class="nav-item"><a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed"><i class="fe fe-feed"></i></a></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"> <input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body>